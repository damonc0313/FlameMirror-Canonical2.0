"""Code generation utilities for the FlameMirror agent."""

from __future__ import annotations

from dataclasses import dataclass, field
from pathlib import Path
from typing import TYPE_CHECKING, Dict, Optional, Sequence, TypedDict, cast

from .ml.model import GraphformicCoder


class GenerationDiagnostics(TypedDict):
    """Structured metadata describing a generation attempt."""

    strategy: str
    notes: str


@dataclass(slots=True)
class GenerationResult:
    """Represents the output of a code generation step."""

    code: str
    target_path: Path
    used_ml: bool
    diagnostics: GenerationDiagnostics = field(
        default_factory=lambda: cast(GenerationDiagnostics, {"strategy": "template", "notes": ""})
    )


class CodeGenerator:
    """Generate code artifacts using templates or the GraphformicCoder backend."""

    def __init__(
        self,
        workspace: Path,
        *,
        ml_model: Optional[GraphformicCoder] = None,
        templates: Optional[Dict[str, str]] = None,
    ) -> None:
        self.workspace = Path(workspace)
        self.workspace.mkdir(parents=True, exist_ok=True)
        self.ml_model = ml_model
        self.templates: Dict[str, str] = templates or {}
        self._ml_enabled = ml_model is not None

    @property
    def ml_enabled(self) -> bool:
        return self._ml_enabled and self.ml_model is not None

    def enable_ml(self, enabled: bool) -> None:
        self._ml_enabled = enabled

    def register_template(self, name: str, template: str) -> None:
        self.templates[name] = template

    def generate(
        self,
        plan_step: "PlanStep",
        *,
        context_lines: Optional[Sequence[str]] = None,
    ) -> GenerationResult:
        """Generate code for the provided plan step."""

        prompt = self._build_prompt(plan_step, context_lines)
        if self.ml_enabled:
            assert self.ml_model is not None
            code = self.ml_model.generate(prompt, plan_step.metadata.get("ast"))
            diagnostics = GenerationDiagnostics(
                strategy="ml",
                notes="Generated via GraphformicCoder",
            )
            used_ml = True
        else:
            code = self._fallback_code(plan_step, prompt)
            diagnostics = GenerationDiagnostics(
                strategy="template",
                notes="Fallback generator used",
            )
            used_ml = False

        target_path = self.workspace / plan_step.target_file
        target_path.parent.mkdir(parents=True, exist_ok=True)
        target_path.write_text(code, encoding="utf-8")
        return GenerationResult(
            code=code,
            target_path=target_path,
            used_ml=used_ml,
            diagnostics=diagnostics,
        )

    def _build_prompt(self, plan_step: "PlanStep", context_lines: Optional[Sequence[str]]) -> str:
        context = "\n".join(context_lines or [])
        prompt = (
            f"Task: {plan_step.description}\n"
            f"Target: {plan_step.target_file}\n"
            f"Priority: {plan_step.priority}\n"
        )
        if context:
            prompt += f"Context:\n{context}\n"
        return prompt

    def _fallback_code(self, plan_step: "PlanStep", prompt: str) -> str:
        template_key = plan_step.metadata.get("template")
        if template_key and template_key in self.templates:
            body = self.templates[template_key]
        else:
            function_name = self._sanitise_identifier(plan_step.description)
            body = (
                f"def {function_name}():\n"
                f"    \"\"\"Autogenerated step for: {plan_step.description}.\"\"\"\n"
                f"    return {plan_step.priority}\n"
            )
        rendered_prompt = prompt.replace("\n", "\n# ")
        header = f"# === FlameMirror Generation ===\n# prompt:\n# {rendered_prompt}\n\n"
        return header + body

    def _sanitise_identifier(self, description: str) -> str:
        cleaned = "_".join(part for part in description.lower().split() if part.isidentifier())
        return cleaned or "generated_step"

if TYPE_CHECKING:
    from .autonomous_agent import PlanStep
